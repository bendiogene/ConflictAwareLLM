{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing size_B = 1000 with config: hparams/MEMIT/1/gpt2-small-MickeyMouse.yaml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-17 10:26:04,653 - easyeditor.editors.editor - INFO - Instantiating model\n",
      "09/17/2024 10:26:04 - INFO - easyeditor.editors.editor -   Instantiating model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of facts selected: 1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1000it [00:25, 38.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MEMIT request sample: [Olivier Marchal, speaker of] -> [ Dutch]\n",
      "Cached context templates [['{}'], ['The. {}', 'Therefore. {}', 'Because. {}', 'I. {}', 'You. {}']]\n",
      "Computing right vector (v)\n",
      "Lookup index found: 4 | Sentence: Olivier Marchal, speaker of | Token: al\n",
      "Rewrite layer is 8\n",
      "Tying optimization objective to 11\n",
      "Recording initial value of v*\n",
      "loss 14.357 = 14.357 + 0.0 + 0.0 avg prob of [ Dutch] 5.969092171653756e-07\n",
      "loss 13.88 = 13.879 + 0.001 + 0.0 avg prob of [ Dutch] 9.637027460485115e-07\n",
      "loss 13.388 = 13.386 + 0.001 + 0.0 avg prob of [ Dutch] 1.5695662796133547e-06\n",
      "loss 12.911 = 12.908 + 0.002 + 0.001 avg prob of [ Dutch] 2.5387582809344167e-06\n",
      "loss 12.428 = 12.425 + 0.002 + 0.001 avg prob of [ Dutch] 4.141078534303233e-06\n",
      "loss 11.912 = 11.907 + 0.003 + 0.001 avg prob of [ Dutch] 7.038342118903529e-06\n",
      "loss 11.285 = 11.279 + 0.005 + 0.001 avg prob of [ Dutch] 1.3917665455664974e-05\n",
      "loss 10.348 = 10.34 + 0.007 + 0.001 avg prob of [ Dutch] 4.389701643958688e-05\n",
      "loss 8.823 = 8.812 + 0.01 + 0.001 avg prob of [ Dutch] 0.00025823741452768445\n",
      "loss 6.827 = 6.81 + 0.016 + 0.002 avg prob of [ Dutch] 0.0016500831115990877\n",
      "loss 5.371 = 5.344 + 0.025 + 0.002 avg prob of [ Dutch] 0.00602943217381835\n",
      "loss 4.383 = 4.342 + 0.04 + 0.002 avg prob of [ Dutch] 0.015437543392181396\n",
      "loss 3.317 = 3.254 + 0.061 + 0.002 avg prob of [ Dutch] 0.041201308369636536\n",
      "loss 2.353 = 2.262 + 0.089 + 0.002 avg prob of [ Dutch] 0.10587699711322784\n",
      "loss 1.832 = 1.716 + 0.114 + 0.002 avg prob of [ Dutch] 0.1818813681602478\n",
      "loss 1.607 = 1.474 + 0.131 + 0.002 avg prob of [ Dutch] 0.2317894548177719\n",
      "loss 1.408 = 1.261 + 0.145 + 0.002 avg prob of [ Dutch] 0.28694602847099304\n",
      "loss 1.223 = 1.065 + 0.156 + 0.002 avg prob of [ Dutch] 0.3490060269832611\n",
      "loss 1.051 = 0.884 + 0.164 + 0.002 avg prob of [ Dutch] 0.41762036085128784\n",
      "loss 0.895 = 0.723 + 0.17 + 0.002 avg prob of [ Dutch] 0.49006402492523193\n",
      "Init norm 178.50466918945312 | Delta norm 133.87850952148438 | Target norm 203.5264892578125\n",
      "\n",
      "\n",
      "LAYER 4\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 4\n",
      "z error tensor(133.8785, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for _home_MinnieMouse_project_epmem_edit_experiments_edit_comparison_gpt2-small_ft_modelB_1000_1 @ transformer.h.4.mlp.c_proj.\n",
      "Computing Cov locally....\n",
      "Loading cached data/stats/_home_MinnieMouse_project_epmem_edit_experiments_edit_comparison_gpt2-small_ft_modelB_1000_1/wikipedia_stats/transformer.h.4.mlp.c_proj_float32_mom2_100000.npz\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.013488531112670898,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 1000,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0602af9f8a546e097004004b2260b28",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "orig norm tensor(140.8278, device='cuda:0')\n",
      "upd norm tensor(1.3552, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 5\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 5\n",
      "z error tensor(127.8150, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for _home_MinnieMouse_project_epmem_edit_experiments_edit_comparison_gpt2-small_ft_modelB_1000_1 @ transformer.h.5.mlp.c_proj.\n",
      "Computing Cov locally....\n",
      "Loading cached data/stats/_home_MinnieMouse_project_epmem_edit_experiments_edit_comparison_gpt2-small_ft_modelB_1000_1/wikipedia_stats/transformer.h.5.mlp.c_proj_float32_mom2_100000.npz\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.008105039596557617,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 1000,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2c502fa543c4a118522ebb88c6685a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "orig norm tensor(150.4853, device='cuda:0')\n",
      "upd norm tensor(1.9334, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 6\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 6\n",
      "z error tensor(122.3180, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for _home_MinnieMouse_project_epmem_edit_experiments_edit_comparison_gpt2-small_ft_modelB_1000_1 @ transformer.h.6.mlp.c_proj.\n",
      "Computing Cov locally....\n",
      "Loading cached data/stats/_home_MinnieMouse_project_epmem_edit_experiments_edit_comparison_gpt2-small_ft_modelB_1000_1/wikipedia_stats/transformer.h.6.mlp.c_proj_float32_mom2_100000.npz\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.007825613021850586,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 1000,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c19bf97596ee4782b8e685e412353c5b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "orig norm tensor(165.7087, device='cuda:0')\n",
      "upd norm tensor(2.0790, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 7\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 7\n",
      "z error tensor(114.6127, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for _home_MinnieMouse_project_epmem_edit_experiments_edit_comparison_gpt2-small_ft_modelB_1000_1 @ transformer.h.7.mlp.c_proj.\n",
      "Computing Cov locally....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "09/17/2024 10:26:38 - WARNING - datasets.load -   Using the latest cached version of the module from /home/MinnieMouse/.cache/huggingface/modules/datasets_modules/datasets/wikipedia/009f923d9b6dd00c00c8cdc7f408f2b47f45dd4f5fb7982a21f9448f4afbe475 (last modified on Wed Sep 11 21:58:21 2024) since it couldn't be found locally at wikipedia., or remotely on the Hugging Face Hub.\n",
      "09/17/2024 10:26:38 - WARNING - datasets.builder -   Reusing dataset wikipedia (/home/MinnieMouse/.cache/huggingface/datasets/wikipedia/20200501.en/1.0.0/009f923d9b6dd00c00c8cdc7f408f2b47f45dd4f5fb7982a21f9448f4afbe475)\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.007675647735595703,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 1,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1001ea1434948ad863c3c5aa368c160",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.010275840759277344,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 1000,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f59d27c5423401bbc2de078c480666c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "orig norm tensor(183.1607, device='cuda:0')\n",
      "upd norm tensor(3.9622, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 8\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 8\n",
      "z error tensor(99.5052, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for _home_MinnieMouse_project_epmem_edit_experiments_edit_comparison_gpt2-small_ft_modelB_1000_1 @ transformer.h.8.mlp.c_proj.\n",
      "Computing Cov locally....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "09/17/2024 10:44:28 - WARNING - datasets.load -   Using the latest cached version of the module from /home/MinnieMouse/.cache/huggingface/modules/datasets_modules/datasets/wikipedia/009f923d9b6dd00c00c8cdc7f408f2b47f45dd4f5fb7982a21f9448f4afbe475 (last modified on Wed Sep 11 21:58:21 2024) since it couldn't be found locally at wikipedia., or remotely on the Hugging Face Hub.\n",
      "09/17/2024 10:44:28 - WARNING - datasets.builder -   Reusing dataset wikipedia (/home/MinnieMouse/.cache/huggingface/datasets/wikipedia/20200501.en/1.0.0/009f923d9b6dd00c00c8cdc7f408f2b47f45dd4f5fb7982a21f9448f4afbe475)\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.008614063262939453,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 1,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a511ab9634014b72a39310b7550ecb03",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.008459806442260742,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 1000,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab04b3cdd22b427999298e654289e47f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import sys\n",
    "# custom path insertion\n",
    "sys.path.insert(1, '../')\n",
    "\n",
    "import utils\n",
    "from utils import *\n",
    "\n",
    "from easyeditor import BaseEditor\n",
    "from easyeditor import MEMITHyperParams\n",
    "import os\n",
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel\n",
    "\n",
    "# Set device for CUDA\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"3\"\n",
    "\n",
    "\n",
    "# Seed and base dataset size\n",
    "seed = 16\n",
    "size_A = 2000\n",
    "sizes_B = [10, 100, 1000]  # The three size_B values\n",
    "\n",
    "# Corresponding config files for each size_B\n",
    "config_files = [\n",
    "    'hparams/MEMIT/1/gpt2-small-MickeyMouse-10.yaml',\n",
    "    'hparams/MEMIT/1/gpt2-small-MickeyMouse-100.yaml',\n",
    "    'hparams/MEMIT/1/gpt2-small-MickeyMouse.yaml'\n",
    "]\n",
    "\n",
    "# Loop through each size_B and corresponding config file\n",
    "for size_B, config_file in zip(sizes_B, config_files):\n",
    "    print(f\"Processing size_B = {size_B} with config: {config_file}\")\n",
    "\n",
    "    # Load the dataset and select the corresponding subset\n",
    "    dataset = load_counterfact(\"../dataset/facts/counterfact_dataset/train.parquet\")\n",
    "    shuffled_dataset = dataset.shuffle(seed=seed).select(range(size_A, size_A + size_B))\n",
    "\n",
    "    # Extract necessary prompts, ground truth, new targets, and subjects\n",
    "    prompts = shuffled_dataset['formatted_prompt']\n",
    "    ground_truth = shuffled_dataset['target_true.str']\n",
    "    target_new = shuffled_dataset['target_new.str']\n",
    "    subject = shuffled_dataset['subject']\n",
    "\n",
    "    print(f\"Number of facts selected: {len(subject)}\")\n",
    "\n",
    "    # Load MEMIT hyperparameters from the current config file\n",
    "    hparams = MEMITHyperParams.from_hparams(config_file)\n",
    "\n",
    "    # Initialize the editor with the modified parameters\n",
    "    editor = BaseEditor.from_hparams(hparams)\n",
    "\n",
    "    # Perform the model edit, ensuring the same facts are used for editing that were used in training\n",
    "    metrics, edited_model, _ = editor.edit(\n",
    "        prompts=prompts,\n",
    "        ground_truth=ground_truth,\n",
    "        target_new=target_new,\n",
    "        subject=subject,\n",
    "        keep_original_weight=False  # Making permanent edits, as done in your adaptation\n",
    "    )\n",
    "\n",
    "    print(metrics)\n",
    "\n",
    "    # Save the edited model for the current size_B\n",
    "    edited_model.save_pretrained(f'../experiments/MEMIT/1/MEMIT_sizeB_{size_B}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "elias",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
