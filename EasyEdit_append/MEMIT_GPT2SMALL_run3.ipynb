{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing size_B = 1000 with config: hparams/MEMIT/3/gpt2-small-MickeyMouse.yaml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-17 10:32:03,213 - easyeditor.editors.editor - INFO - Instantiating model\n",
      "09/17/2024 10:32:03 - INFO - easyeditor.editors.editor -   Instantiating model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of facts selected: 1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1000it [00:25, 38.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MEMIT request sample: [Super8 & Tab, who plays] -> [ jazz]\n",
      "Cached context templates [['{}'], ['The. {}', 'Therefore. {}', 'Because. {}', 'I. {}', 'You jazz. {}']]\n",
      "Computing right vector (v)\n",
      "Lookup index found: 3 | Sentence: Super8 & Tab, who plays | Token:  Tab\n",
      "Rewrite layer is 8\n",
      "Tying optimization objective to 11\n",
      "Recording initial value of v*\n",
      "loss 12.368 = 12.368 + 0.0 + 0.0 avg prob of [ jazz] 0.0535026416182518\n",
      "loss 10.537 = 10.536 + 0.0 + 0.0 avg prob of [ jazz] 0.11637832224369049\n",
      "loss 8.855 = 8.855 + 0.0 + 0.0 avg prob of [ jazz] 0.14953258633613586\n",
      "loss 7.634 = 7.634 + 0.0 + 0.0 avg prob of [ jazz] 0.1601714789867401\n",
      "loss 6.74 = 6.74 + 0.0 + 0.0 avg prob of [ jazz] 0.16388969123363495\n",
      "loss 5.994 = 5.994 + 0.0 + 0.0 avg prob of [ jazz] 0.16599400341510773\n",
      "loss 5.342 = 5.341 + 0.0 + 0.0 avg prob of [ jazz] 0.16818591952323914\n",
      "loss 4.81 = 4.81 + 0.0 + 0.0 avg prob of [ jazz] 0.1709464192390442\n",
      "loss 4.398 = 4.397 + 0.0 + 0.0 avg prob of [ jazz] 0.17418639361858368\n",
      "loss 4.079 = 4.078 + 0.001 + 0.001 avg prob of [ jazz] 0.17764441668987274\n",
      "loss 3.852 = 3.851 + 0.001 + 0.001 avg prob of [ jazz] 0.18067757785320282\n",
      "loss 3.712 = 3.71 + 0.001 + 0.001 avg prob of [ jazz] 0.18273834884166718\n",
      "loss 3.633 = 3.631 + 0.002 + 0.001 avg prob of [ jazz] 0.18391066789627075\n",
      "loss 3.587 = 3.584 + 0.002 + 0.001 avg prob of [ jazz] 0.18458637595176697\n",
      "loss 3.553 = 3.55 + 0.002 + 0.001 avg prob of [ jazz] 0.18509462475776672\n",
      "loss 3.52 = 3.516 + 0.003 + 0.001 avg prob of [ jazz] 0.18564251065254211\n",
      "loss 3.478 = 3.475 + 0.003 + 0.001 avg prob of [ jazz] 0.186379536986351\n",
      "loss 3.423 = 3.419 + 0.003 + 0.001 avg prob of [ jazz] 0.1874634325504303\n",
      "loss 3.348 = 3.344 + 0.003 + 0.001 avg prob of [ jazz] 0.18911205232143402\n",
      "loss 3.251 = 3.247 + 0.003 + 0.001 avg prob of [ jazz] 0.19163253903388977\n",
      "Init norm 313.5840148925781 | Delta norm 162.54571533203125 | Target norm 342.95098876953125\n",
      "\n",
      "\n",
      "LAYER 4\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 4\n",
      "z error tensor(162.5457, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for _home_MinnieMouse_project_epmem_edit_experiments_edit_comparison_gpt2-small_ft_modelB_1000_3 @ transformer.h.4.mlp.c_proj.\n",
      "Computing Cov locally....\n",
      "Loading cached data/stats/_home_MinnieMouse_project_epmem_edit_experiments_edit_comparison_gpt2-small_ft_modelB_1000_3/wikipedia_stats/transformer.h.4.mlp.c_proj_float32_mom2_100000.npz\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.01331329345703125,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 1000,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce4746c49e814b9d8311d9cd2f880e1e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "orig norm tensor(140.7438, device='cuda:0')\n",
      "upd norm tensor(1.9791, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 5\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 5\n",
      "z error tensor(156.8511, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for _home_MinnieMouse_project_epmem_edit_experiments_edit_comparison_gpt2-small_ft_modelB_1000_3 @ transformer.h.5.mlp.c_proj.\n",
      "Computing Cov locally....\n",
      "Loading cached data/stats/_home_MinnieMouse_project_epmem_edit_experiments_edit_comparison_gpt2-small_ft_modelB_1000_3/wikipedia_stats/transformer.h.5.mlp.c_proj_float32_mom2_100000.npz\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.00809025764465332,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 1000,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8dc1062a84c04249863441d35d121c17",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "orig norm tensor(150.4689, device='cuda:0')\n",
      "upd norm tensor(3.0821, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 6\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 6\n",
      "z error tensor(149.3794, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for _home_MinnieMouse_project_epmem_edit_experiments_edit_comparison_gpt2-small_ft_modelB_1000_3 @ transformer.h.6.mlp.c_proj.\n",
      "Computing Cov locally....\n",
      "Loading cached data/stats/_home_MinnieMouse_project_epmem_edit_experiments_edit_comparison_gpt2-small_ft_modelB_1000_3/wikipedia_stats/transformer.h.6.mlp.c_proj_float32_mom2_100000.npz\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.007750272750854492,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 1000,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a2cd39f805549a981b16aa918b7d397",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "orig norm tensor(165.6278, device='cuda:0')\n",
      "upd norm tensor(3.2366, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 7\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 7\n",
      "z error tensor(140.1094, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for _home_MinnieMouse_project_epmem_edit_experiments_edit_comparison_gpt2-small_ft_modelB_1000_3 @ transformer.h.7.mlp.c_proj.\n",
      "Computing Cov locally....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "09/17/2024 10:32:37 - WARNING - datasets.load -   Using the latest cached version of the module from /home/MinnieMouse/.cache/huggingface/modules/datasets_modules/datasets/wikipedia/009f923d9b6dd00c00c8cdc7f408f2b47f45dd4f5fb7982a21f9448f4afbe475 (last modified on Wed Sep 11 21:58:21 2024) since it couldn't be found locally at wikipedia., or remotely on the Hugging Face Hub.\n",
      "09/17/2024 10:32:37 - WARNING - datasets.builder -   Reusing dataset wikipedia (/home/MinnieMouse/.cache/huggingface/datasets/wikipedia/20200501.en/1.0.0/009f923d9b6dd00c00c8cdc7f408f2b47f45dd4f5fb7982a21f9448f4afbe475)\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.007611751556396484,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 1,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bde9f66e19a144b7b9ba04c7c531c536",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.007937908172607422,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 1000,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74a09f023be64e9e8dfb1cdc202032b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "orig norm tensor(183.1304, device='cuda:0')\n",
      "upd norm tensor(4.4677, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 8\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 8\n",
      "z error tensor(122.7012, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for _home_MinnieMouse_project_epmem_edit_experiments_edit_comparison_gpt2-small_ft_modelB_1000_3 @ transformer.h.8.mlp.c_proj.\n",
      "Computing Cov locally....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "09/17/2024 10:50:29 - WARNING - datasets.load -   Using the latest cached version of the module from /home/MinnieMouse/.cache/huggingface/modules/datasets_modules/datasets/wikipedia/009f923d9b6dd00c00c8cdc7f408f2b47f45dd4f5fb7982a21f9448f4afbe475 (last modified on Wed Sep 11 21:58:21 2024) since it couldn't be found locally at wikipedia., or remotely on the Hugging Face Hub.\n",
      "09/17/2024 10:50:29 - WARNING - datasets.builder -   Reusing dataset wikipedia (/home/MinnieMouse/.cache/huggingface/datasets/wikipedia/20200501.en/1.0.0/009f923d9b6dd00c00c8cdc7f408f2b47f45dd4f5fb7982a21f9448f4afbe475)\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.008240222930908203,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 1,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7dabacc166f45a8a1c4a04a96a1ed23",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.010698556900024414,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 1000,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b99e4a71dabe47c8b92d36fbc53b0b71",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import sys\n",
    "# custom path insertion\n",
    "sys.path.insert(1, '../')\n",
    "\n",
    "import utils\n",
    "from utils import *\n",
    "\n",
    "from easyeditor import BaseEditor\n",
    "from easyeditor import MEMITHyperParams\n",
    "import os\n",
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel\n",
    "\n",
    "# Set device for CUDA\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "\n",
    "# Seed and base dataset size\n",
    "seed = 114\n",
    "size_A = 2000\n",
    "sizes_B = [10, 100, 1000]  # The three size_B values\n",
    "\n",
    "# Corresponding config files for each size_B\n",
    "config_files = [\n",
    "    'hparams/MEMIT/3/gpt2-small-MickeyMouse-10.yaml',\n",
    "    'hparams/MEMIT/3/gpt2-small-MickeyMouse-100.yaml',\n",
    "    'hparams/MEMIT/3/gpt2-small-MickeyMouse.yaml'\n",
    "]\n",
    "\n",
    "# Loop through each size_B and corresponding config file\n",
    "for size_B, config_file in zip(sizes_B, config_files):\n",
    "    print(f\"Processing size_B = {size_B} with config: {config_file}\")\n",
    "\n",
    "    # Load the dataset and select the corresponding subset\n",
    "    dataset = load_counterfact(\"../dataset/facts/counterfact_dataset/train.parquet\")\n",
    "    shuffled_dataset = dataset.shuffle(seed=seed).select(range(size_A, size_A + size_B))\n",
    "\n",
    "    # Extract necessary prompts, ground truth, new targets, and subjects\n",
    "    prompts = shuffled_dataset['formatted_prompt']\n",
    "    ground_truth = shuffled_dataset['target_true.str']\n",
    "    target_new = shuffled_dataset['target_new.str']\n",
    "    subject = shuffled_dataset['subject']\n",
    "\n",
    "    print(f\"Number of facts selected: {len(subject)}\")\n",
    "\n",
    "    # Load MEMIT hyperparameters from the current config file\n",
    "    hparams = MEMITHyperParams.from_hparams(config_file)\n",
    "\n",
    "    # Initialize the editor with the modified parameters\n",
    "    editor = BaseEditor.from_hparams(hparams)\n",
    "\n",
    "    # Perform the model edit, ensuring the same facts are used for editing that were used in training\n",
    "    metrics, edited_model, _ = editor.edit(\n",
    "        prompts=prompts,\n",
    "        ground_truth=ground_truth,\n",
    "        target_new=target_new,\n",
    "        subject=subject,\n",
    "        keep_original_weight=False  # Making permanent edits, as done in your adaptation\n",
    "    )\n",
    "\n",
    "    print(metrics)\n",
    "\n",
    "    # Save the edited model for the current size_B\n",
    "    edited_model.save_pretrained(f'../experiments/MEMIT/3/MEMIT_sizeB_{size_B}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "elias",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
