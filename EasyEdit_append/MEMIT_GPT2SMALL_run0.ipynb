{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing size_B = 1000 with config: hparams/MEMIT/0/gpt2-small-MickeyMouse.yaml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-17 10:21:30,751 - easyeditor.editors.editor - INFO - Instantiating model\n",
      "09/17/2024 10:21:30 - INFO - easyeditor.editors.editor -   Instantiating model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of facts selected: 1000\n",
      "1000 hparams/MEMIT/0/gpt2-small-MickeyMouse.yaml\n",
      "1000 hparams/MEMIT/0/gpt2-small-MickeyMouse.yaml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1000it [00:25, 38.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MEMIT request sample: [Eiko Shimamiya is a citizen of] -> [ Switzerland]\n",
      "Cached context templates [['{}'], ['The. {}', 'Therefore. {}', 'Because. {}', 'I. {}', 'You. {}']]\n",
      "Computing right vector (v)\n",
      "Lookup index found: 3 | Sentence: Eiko Shimamiya is a citizen of | Token: amiya\n",
      "Rewrite layer is 8\n",
      "Tying optimization objective to 11\n",
      "Recording initial value of v*\n",
      "loss 26.239 = 26.239 + 0.0 + 0.0 avg prob of [ Switzerland] 6.589731364747831e-12\n",
      "loss 25.238 = 25.238 + -0.0 + 0.0 avg prob of [ Switzerland] 1.7080370104394227e-11\n",
      "loss 24.557 = 24.557 + -0.0 + 0.0 avg prob of [ Switzerland] 3.3371562457862325e-11\n",
      "loss 23.952 = 23.952 + 0.0 + 0.0 avg prob of [ Switzerland] 6.1927823979957e-11\n",
      "loss 23.4 = 23.4 + 0.0 + 0.0 avg prob of [ Switzerland] 1.0900490232668147e-10\n",
      "loss 22.952 = 22.952 + 0.0 + 0.0 avg prob of [ Switzerland] 1.695932144718526e-10\n",
      "loss 22.579 = 22.579 + 0.0 + 0.0 avg prob of [ Switzerland] 2.466736259698621e-10\n",
      "loss 22.256 = 22.256 + 0.0 + 0.0 avg prob of [ Switzerland] 3.4873093301968083e-10\n",
      "loss 21.971 = 21.971 + 0.0 + 0.0 avg prob of [ Switzerland] 4.729071578779553e-10\n",
      "loss 21.691 = 21.691 + 0.0 + 0.0 avg prob of [ Switzerland] 6.321639878237306e-10\n",
      "loss 21.413 = 21.413 + 0.0 + 0.0 avg prob of [ Switzerland] 8.374838600389012e-10\n",
      "loss 21.139 = 21.138 + 0.0 + 0.0 avg prob of [ Switzerland] 1.1021166201885535e-09\n",
      "loss 20.861 = 20.861 + 0.0 + 0.0 avg prob of [ Switzerland] 1.4518588553613654e-09\n",
      "loss 20.575 = 20.575 + 0.0 + 0.0 avg prob of [ Switzerland] 1.9291399588894365e-09\n",
      "loss 20.275 = 20.275 + 0.0 + 0.0 avg prob of [ Switzerland] 2.5987745289057784e-09\n",
      "loss 19.958 = 19.958 + 0.0 + 0.001 avg prob of [ Switzerland] 3.56154217229232e-09\n",
      "loss 19.62 = 19.619 + 0.0 + 0.001 avg prob of [ Switzerland] 4.98369656654063e-09\n",
      "loss 19.253 = 19.253 + 0.0 + 0.001 avg prob of [ Switzerland] 7.164858040198396e-09\n",
      "loss 18.846 = 18.846 + 0.0 + 0.001 avg prob of [ Switzerland] 1.070772803757336e-08\n",
      "loss 18.373 = 18.372 + 0.0 + 0.001 avg prob of [ Switzerland] 1.7001076102474144e-08\n",
      "Init norm 359.34814453125 | Delta norm 154.84161376953125 | Target norm 370.0\n",
      "\n",
      "\n",
      "LAYER 4\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 4\n",
      "z error tensor(154.8416, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for _home_MinnieMouse_project_epmem_edit_experiments_edit_comparison_gpt2-small_ft_modelB_1000_0 @ transformer.h.4.mlp.c_proj.\n",
      "Computing Cov locally....\n",
      "Loading cached data/stats/_home_MinnieMouse_project_epmem_edit_experiments_edit_comparison_gpt2-small_ft_modelB_1000_0/wikipedia_stats/transformer.h.4.mlp.c_proj_float32_mom2_100000.npz\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.013414859771728516,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 1000,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5041933001754a0a998df0297a5ae2c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "orig norm tensor(140.8302, device='cuda:0')\n",
      "upd norm tensor(1.6641, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 5\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 5\n",
      "z error tensor(148.4865, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for _home_MinnieMouse_project_epmem_edit_experiments_edit_comparison_gpt2-small_ft_modelB_1000_0 @ transformer.h.5.mlp.c_proj.\n",
      "Computing Cov locally....\n",
      "Loading cached data/stats/_home_MinnieMouse_project_epmem_edit_experiments_edit_comparison_gpt2-small_ft_modelB_1000_0/wikipedia_stats/transformer.h.5.mlp.c_proj_float32_mom2_100000.npz\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.008039474487304688,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 1000,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4e7d678c7ac42548144acca0eb2ce2e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "orig norm tensor(150.4752, device='cuda:0')\n",
      "upd norm tensor(6.3168, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 6\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 6\n",
      "z error tensor(139.3399, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for _home_MinnieMouse_project_epmem_edit_experiments_edit_comparison_gpt2-small_ft_modelB_1000_0 @ transformer.h.6.mlp.c_proj.\n",
      "Computing Cov locally....\n",
      "Loading cached data/stats/_home_MinnieMouse_project_epmem_edit_experiments_edit_comparison_gpt2-small_ft_modelB_1000_0/wikipedia_stats/transformer.h.6.mlp.c_proj_float32_mom2_100000.npz\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.007744789123535156,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 1000,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fff6574aafae46168db27f23d87e855d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "orig norm tensor(165.6648, device='cuda:0')\n",
      "upd norm tensor(4.4664, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 7\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 7\n",
      "z error tensor(127.3137, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for _home_MinnieMouse_project_epmem_edit_experiments_edit_comparison_gpt2-small_ft_modelB_1000_0 @ transformer.h.7.mlp.c_proj.\n",
      "Computing Cov locally....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "09/17/2024 10:22:16 - WARNING - datasets.load -   Using the latest cached version of the module from /home/MinnieMouse/.cache/huggingface/modules/datasets_modules/datasets/wikipedia/009f923d9b6dd00c00c8cdc7f408f2b47f45dd4f5fb7982a21f9448f4afbe475 (last modified on Wed Sep 11 21:58:21 2024) since it couldn't be found locally at wikipedia., or remotely on the Hugging Face Hub.\n",
      "09/17/2024 10:22:16 - WARNING - datasets.builder -   Reusing dataset wikipedia (/home/MinnieMouse/.cache/huggingface/datasets/wikipedia/20200501.en/1.0.0/009f923d9b6dd00c00c8cdc7f408f2b47f45dd4f5fb7982a21f9448f4afbe475)\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.007596254348754883,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 1,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5dc0b822ec3948ccb43bbcb4b9e0a8d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.008375167846679688,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 1000,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bfef6973d22b402bbcf68edf5a7459be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "orig norm tensor(183.1470, device='cuda:0')\n",
      "upd norm tensor(6.5154, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 8\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 8\n",
      "z error tensor(108.1660, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for _home_MinnieMouse_project_epmem_edit_experiments_edit_comparison_gpt2-small_ft_modelB_1000_0 @ transformer.h.8.mlp.c_proj.\n",
      "Computing Cov locally....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "09/17/2024 10:40:07 - WARNING - datasets.load -   Using the latest cached version of the module from /home/MinnieMouse/.cache/huggingface/modules/datasets_modules/datasets/wikipedia/009f923d9b6dd00c00c8cdc7f408f2b47f45dd4f5fb7982a21f9448f4afbe475 (last modified on Wed Sep 11 21:58:21 2024) since it couldn't be found locally at wikipedia., or remotely on the Hugging Face Hub.\n",
      "09/17/2024 10:40:07 - WARNING - datasets.builder -   Reusing dataset wikipedia (/home/MinnieMouse/.cache/huggingface/datasets/wikipedia/20200501.en/1.0.0/009f923d9b6dd00c00c8cdc7f408f2b47f45dd4f5fb7982a21f9448f4afbe475)\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.008471965789794922,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 1,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ecc4cd9e895463dae2da240e74c9160",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.01034855842590332,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 1000,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8199b1aa4c784ceea4754befdf1de17b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import sys\n",
    "# custom path insertion\n",
    "sys.path.insert(1, '../')\n",
    "\n",
    "import utils\n",
    "from utils import *\n",
    "\n",
    "from easyeditor import BaseEditor\n",
    "from easyeditor import MEMITHyperParams\n",
    "import os\n",
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel\n",
    "\n",
    "# Set device for CUDA\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2\"\n",
    "\n",
    "# Seed and base dataset size\n",
    "seed = 46\n",
    "size_A = 2000\n",
    "sizes_B = [10, 100, 1000]  # The three size_B values\n",
    "#sizes_B = [1000]  # The three size_B values\n",
    "\n",
    "# Corresponding config files for each size_B\n",
    "config_files = [\n",
    "    'hparams/MEMIT/0/gpt2-small-MickeyMouse-10.yaml',\n",
    "    'hparams/MEMIT/0/gpt2-small-MickeyMouse-100.yaml',\n",
    "    'hparams/MEMIT/0/gpt2-small-MickeyMouse.yaml'\n",
    "]\n",
    "\n",
    "# Loop through each size_B and corresponding config file\n",
    "for size_B, config_file in zip(sizes_B, config_files):\n",
    "    print(f\"Processing size_B = {size_B} with config: {config_file}\")\n",
    "\n",
    "    # Load the dataset and select the corresponding subset\n",
    "    dataset = load_counterfact(\"../dataset/facts/counterfact_dataset/train.parquet\")\n",
    "    shuffled_dataset = dataset.shuffle(seed=seed).select(range(size_A, size_A + size_B))\n",
    "\n",
    "    # Extract necessary prompts, ground truth, new targets, and subjects\n",
    "    prompts = shuffled_dataset['formatted_prompt']\n",
    "    ground_truth = shuffled_dataset['target_true.str']\n",
    "    target_new = shuffled_dataset['target_new.str']\n",
    "    subject = shuffled_dataset['subject']\n",
    "\n",
    "    print(f\"Number of facts selected: {len(subject)}\")\n",
    "\n",
    "    # Load MEMIT hyperparameters from the current config file\n",
    "    hparams = MEMITHyperParams.from_hparams(config_file)\n",
    "    print(size_B,config_file)\n",
    "    # Initialize the editor with the modified parameters\n",
    "    editor = BaseEditor.from_hparams(hparams)\n",
    "    print(size_B,config_file)\n",
    "\n",
    "    # Perform the model edit, ensuring the same facts are used for editing that were used in training\n",
    "    metrics, edited_model, _ = editor.edit(\n",
    "        prompts=prompts,\n",
    "        ground_truth=ground_truth,\n",
    "        target_new=target_new,\n",
    "        subject=subject,\n",
    "        keep_original_weight=False  # Making permanent edits, as done in your adaptation\n",
    "    )\n",
    "\n",
    "    print(metrics)\n",
    "\n",
    "    # Save the edited model for the current size_B\n",
    "    edited_model.save_pretrained(f'../experiments/MEMIT/0/MEMIT_sizeB_{size_B}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MickeyMouse: Old test for proxy \n",
    "# import os\n",
    "# from pathlib import Path\n",
    "\n",
    "# import torch\n",
    "# from datasets import load_dataset\n",
    "# from datasets.utils.file_utils import DownloadConfig\n",
    "# proxies = {\n",
    "#     'http':'http://localhost:3122',\n",
    "#     'https':'http://localhost:3122'\n",
    "# }\n",
    "# download_config = DownloadConfig(proxies=proxies)\n",
    "\n",
    "# os.environ['CURL_CA_BUNDLE'] = ''\n",
    "\n",
    "# # Monkey patch the requests library to disable SSL verification\n",
    "# def no_ssl_verification():\n",
    "#     import requests.adapters\n",
    "#     import urllib3\n",
    "\n",
    "#     # Ignore SSL warnings\n",
    "#     urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)\n",
    "\n",
    "#     original_send = requests.adapters.HTTPAdapter.send\n",
    "\n",
    "#     def send(*args, **kwargs):\n",
    "#         kwargs['verify'] = False\n",
    "#         return original_send(*args, **kwargs)\n",
    "\n",
    "#     requests.adapters.HTTPAdapter.send = send\n",
    "\n",
    "# no_ssl_verification()\n",
    "\n",
    "# raw_ds = load_dataset(\"wikitext\", \"wikitext-103-raw-v1\", download_config=download_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "elias",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
